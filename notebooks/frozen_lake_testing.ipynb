{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "453f6acb",
   "metadata": {},
   "source": [
    "# Frozen Lake Testing\n",
    "\n",
    "Short notebook just playing around with the Frozen Lake environment to get a feel for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be69c8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import TransformAction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab6af37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note is_slippery has a fixed probability of failure\n",
    "# for more flexibility lets wrap the action\n",
    "env = gym.make(\"FrozenLake-v1\", is_slippery=False)\n",
    "env = TransformAction(env, )\n",
    "state, info = env.reset()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919691d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# observation, reward, terminated, truncated, info = env.step(2)\n",
    "# episode_over = terminated or truncated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2cf5aa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "# fmt: off\n",
    "LEFT, DOWN, RIGHT, UP = 0, 1, 2, 3\n",
    "_PERP = {LEFT:  (UP, DOWN), \n",
    "         RIGHT: (UP, DOWN), \n",
    "         UP:    (LEFT, RIGHT), \n",
    "         DOWN:  (LEFT, RIGHT)}\n",
    "SEED = 42\n",
    "# fmt: on\n",
    "\n",
    "class ContinuousSlipWrapper(gym.Wrapper):\n",
    "    \"\"\"\n",
    "    Adds a controllable slip probability to FrozenLake.\n",
    "    Parameters\n",
    "    ----------\n",
    "    slip_prob : float in [0,1]\n",
    "        Probability that the agent's intended action is replaced\n",
    "        by a perpendicular action.\n",
    "    rng : np.random.Generator | None\n",
    "        For reproducibility.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        env: gym.Env,\n",
    "        slip_prob: float = 0.2,\n",
    "        rng: np.random.Generator | None = None,\n",
    "    ) -> None:\n",
    "        assert 0.0 <= slip_prob <= 1.0\n",
    "        super().__init__(env)\n",
    "        self.slip_prob = slip_prob\n",
    "        self.rng = rng or np.random.default_rng()\n",
    "\n",
    "    def _maybe_slip(self, action: int) -> tuple[int, bool, float]:\n",
    "        \"\"\"Return (effective_action, slipped?, probability).\"\"\"\n",
    "        if self.rng.random() < self.slip_prob:\n",
    "            slipped = True\n",
    "            eff_action = self.rng.choice(_PERP[action])\n",
    "            p = self.slip_prob / 2.0  # half the mass on each perpendicular\n",
    "        else:\n",
    "            slipped = False\n",
    "            eff_action = action\n",
    "            p = 1.0 - self.slip_prob\n",
    "        return eff_action, slipped, p\n",
    "\n",
    "    def step(self, action):\n",
    "        eff_action, slipped, p = self._maybe_slip(action)\n",
    "        obs, rew, term, trunc, info = self.env.step(eff_action)\n",
    "\n",
    "        # overwrite / add transition data\n",
    "        info.update(prob=p, slipped=slipped, effective_action=eff_action)\n",
    "\n",
    "        return obs, rew, term, trunc, info\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        obs, info = self.env.reset(**kwargs)\n",
    "        info.update(prob=1.0, slipped=False, effective_action=None)\n",
    "        return obs, info\n",
    "\n",
    "base_env: gym.Env = gym.make(\"FrozenLake-v1\", is_slippery=False)\n",
    "seeded_rng = np.random.default_rng(SEED)\n",
    "env = ContinuousSlipWrapper(base_env, slip_prob=0.15, rng=seeded_rng)\n",
    "\n",
    "obs, info = env.reset()\n",
    "action = 0\n",
    "obs, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "# can handle runtime changes in the slip_prob\n",
    "env.slip_prob=1.0\n",
    "action = 1\n",
    "obs, reward, terminated, truncated, info = env.step(action)\n",
    "assert info['prob'] == 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffa8f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_env(seed):\n",
    "#     def _thunk():\n",
    "#         base = gym.make(\"FrozenLake-v1\", is_slippery=False)\n",
    "#         return ContinuousSlipWrapper(base, slip_prob=0.15,\n",
    "#                                      rng=np.random.default_rng(seed))\n",
    "#     return _thunk\n",
    "\n",
    "# # 1. Build a list of thunks, each with its own seed (and, if you like, its own slip_prob)\n",
    "# num_envs = 8\n",
    "# thunks = [make_env(seed=i) for i in range(num_envs)]\n",
    "\n",
    "# # 2. Create a vectorised environment\n",
    "# vec_env = gym.vector.SyncVectorEnv(thunks)   # or AsyncVectorEnv(thunks)\n",
    "\n",
    "# # 3. Use it like any Gym VecEnv\n",
    "# obs, infos = vec_env.reset()\n",
    "# actions    = np.zeros(num_envs, dtype=int)   # try doing nothing\n",
    "# obs, rews, terms, truncs, infos = vec_env.step(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28764f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# done = False\n",
    "# while not done:\n",
    "#     action = env.action_space.sample()\n",
    "#     obs, reward, terminated, truncated, info = env.step(action)\n",
    "#     done = terminated or truncated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d03e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Sequence\n",
    "\n",
    "_PERP = {0: (1, 3), 1: (0, 2), 2: (1, 3), 3: (0, 2)}\n",
    "\n",
    "type Schedule = float | Sequence[float] | np.ndarray\n",
    "\n",
    "class ContinuousSlipWrapper(gym.Wrapper):\n",
    "    \"\"\"\n",
    "    Wrapper for a *FrozenLake*-style environment whose slip probability can vary\n",
    "    continuously between 0 and 1 and—optionally—follow a user-supplied schedule.\n",
    "\n",
    "    At every reset the wrapper:\n",
    "\n",
    "    * Bumps an internal *episode* counter.\n",
    "    * Sets the current *slip_prob* from the schedule (or leaves it unchanged if\n",
    "      a scalar was supplied).\n",
    "    * Injects diagnostic keys into the ``info`` dict returned by\n",
    "      :py:meth:`reset`.\n",
    "\n",
    "    During :py:meth:`step` it may replace the agent's chosen action by a\n",
    "    perpendicular one with probability ``slip_prob`` and records whether a slip\n",
    "    occurred along with the effective action.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    episode : int\n",
    "        Zero-based episode counter (-1 before the first reset).\n",
    "    slip_prob : float\n",
    "        Current probability that the intended action is replaced by a\n",
    "        perpendicular one.\n",
    "    schedule : Sequence[float] | numpy.ndarray | None\n",
    "        Episode-wise schedule of slip probabilities or *None* when a scalar slip_prob was\n",
    "        given.\n",
    "    rng : numpy.random.Generator\n",
    "        Optional random-number generator used for all stochastic decisions.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The wrapper assumes the underlying environment uses the canonical four\n",
    "    actions: ``0:LEFT, 1:DOWN, 2:RIGHT, 3:UP`` (as in *FrozenLake*). Slips are\n",
    "    sampled independently at every step.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> base_env = gym.make(\"FrozenLake-v1\", is_slippery=False)\n",
    "    >>> env = ContinuousSlipWrapper(base_env, slip_prob=[1.0, 0.5, 0.0])\n",
    "    >>> obs, info = env.reset()\n",
    "    >>> info[\"slip_prob\"]\n",
    "    1.0\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        env: gym.Env,\n",
    "        slip_prob: Schedule = 0.2,\n",
    "        rng: np.random.Generator | None = None,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        env : gym.Env\n",
    "            Environment to wrap. Must implement the four-action *FrozenLake* API.\n",
    "        slip_prob : float | Sequence[float] | numpy.ndarray, default 0.2\n",
    "            *Scalar* Fixed slip probability used for all episodes.\n",
    "\n",
    "            *Sequence / ndarray* Schedule of probabilities applied episode by\n",
    "            episode.  If the agent outlives the schedule, the final value is\n",
    "            held constant thereafter.\n",
    "        rng : numpy.random.Generator, optional\n",
    "            Source of randomness.  When *None* (default) this falls back to\n",
    "            :pyfunc:`numpy.random.default_rng`.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        Only light bookkeeping happens here; the probability is applied in\n",
    "        :py:meth:`step` via :py:meth:`_maybe_slip`.\n",
    "        \"\"\"\n",
    "        super().__init__(env)\n",
    "        self.episode = -1\n",
    "        if isinstance(slip_prob, float):\n",
    "            self.slip_prob = slip_prob      # current value (mutable)\n",
    "            self.schedule = None\n",
    "        elif isinstance(slip_prob, (Sequence, np.ndarray)):\n",
    "            self.schedule = slip_prob\n",
    "            self.slip_prob = slip_prob[0]\n",
    "\n",
    "        self.rng = rng or np.random.default_rng()\n",
    "\n",
    "    # ----- public helpers --------------------------------------------------\n",
    "    def set_slip_prob(self, p: float) -> None:\n",
    "        \"\"\"Override slip probability\"\"\"\n",
    "        self.slip_prob = p\n",
    "\n",
    "    # ----- gym API ----------------------------------------------------------\n",
    "    def reset(self, **kwargs):\n",
    "        self.episode += 1\n",
    "        self.slip_prob = self._scheduled_prob()\n",
    "        obs, info = self.env.reset(**kwargs)\n",
    "        info.update(\n",
    "            prob=1.0,\n",
    "            slipped=False,\n",
    "            effective_action=None,\n",
    "            slip_prob=self.slip_prob,\n",
    "            episode=self.episode,\n",
    "        )\n",
    "        return obs, info\n",
    "\n",
    "    def step(self, action):\n",
    "        eff_action, slipped, p = self._maybe_slip(action)\n",
    "        obs, rew, term, trunc, info = self.env.step(eff_action)\n",
    "        info.update(\n",
    "            prob=p,\n",
    "            slipped=slipped,\n",
    "            effective_action=eff_action,\n",
    "            slip_prob=self.slip_prob,\n",
    "            episode=self.episode,\n",
    "        )\n",
    "        return obs, rew, term, trunc, info\n",
    "\n",
    "    # ----- internals --------------------------------------------------------\n",
    "    def _maybe_slip(self, action: int):\n",
    "        if self.rng.random() < self.slip_prob:\n",
    "            eff_action = self.rng.choice(_PERP[action])\n",
    "            return eff_action, True, self.slip_prob / 2.0\n",
    "        return action, False, 1.0 - self.slip_prob\n",
    "\n",
    "    def _scheduled_prob(self) -> float:\n",
    "        if self.schedule is None:\n",
    "            return self.slip_prob\n",
    "    \n",
    "        if self.episode < len(self.schedule):\n",
    "            return self.schedule[self.episode]\n",
    "        # if the episode is beyond the end of the schedule, just take\n",
    "        # the final value\n",
    "        return self.schedule[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1ca7226c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_env: gym.Env = gym.make(\"FrozenLake-v1\", is_slippery=False)\n",
    "seeded_rng = np.random.default_rng(SEED)\n",
    "env = ContinuousSlipWrapper(base_env, slip_prob=[0.1], rng=seeded_rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "50999683",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7ca6f208",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, _, _, _, info = env.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "18dba790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prob': 0.9,\n",
       " 'slipped': False,\n",
       " 'effective_action': 0,\n",
       " 'slip_prob': 0.1,\n",
       " 'episode': 0}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279d46f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
